# BayesOptim
Bayesian optimization during live neuroscience experiments


# Choosing type of run: `simulation` or `live`
## Simulation
Use the `sim_config.py` script. This is the neuron simulation case. Here, we can run an optimization model on purely simulated neuronal data, experimental data, or experimental data with some simulated tuning curves. Changing the `Neurons` --> `SimPop` parameter (gaussian, bio, or pseudo, respectively) in the YAML file will let you choose which type of data to work with. 

## Improv
As we also interface with **[improv](https://github.com/project-improv/improv)**, running the ~improv~ method will use the `improv_config.py` script. This will be a test case, where the config output parameters will be printed for verification purposes. 

<!-- <a id="preproc"></a>
## Preprocessing
The codes align experimental stimuli and the C arrays (neuron responses) generated by CaImAn package. Run **building_prior.ipynb** in the demo_notebooks section to get AUC for each neuron. Currently the codes supported preprocessing of "drift gratings", "moving dots", "flashing spots". Only von-mises fits are completed for fitting neuron responses to "drift gratings" and "moving dots" stimuli as they are both orientation-related. -->

<a id="run-code"></a>
## Running the code
### Running
The code can be run with specifiying the parameter file of your choosing. The parameter file outlines which data type to use (simulated, experimental, experimental + simulated), Bayesian optimization methods, and secondary methods `online` and `offline` in the config.py file. The `online` method is for typical Bayesian optimization sampling, whereas `offline` is used specifically for PseudoNeuron to calculate the offline fit of the data. To run the code in the terminal, use:
```
python run_simulations.py parameter.yml
```

Running this, will output a `results_dict` which contains the resulting parameters: 

`Pr_list (list)`          : probabilities of correct predictions using Bayes Opt sampling <br>
`mse_final (list)`        : final MSE values for each neuron <br>
`loc_list (list)`         : final predicted peak locations for each neuron <br>
`max_allN (list)`         : predicted peak locations for each test run for each neuron <br>
`stopping_allN (list)`    : stopping value (Expected Improvement value) for for each test for each neuron <br>
`runt_list (list)`        : run time for each neuron <br>
`f_all (list)`            : predicted means <br>
`sigma_all (list)`        : sigmas <br>
`sample_x (list)`         : x samples used <br>
`sample_y (list)`         : y response <br>
`test_time_neuron (list)` : run time for each test for each neuron <br>


### Evaluation
The code also currently has one evaluation method for the manual and BoTorch online methods: left blank for `None` or `eval`. The evaluation mode plots predicted peak locations at each sample for each neuron on the tuning curve, the stopping criteria as a function of time per neuron, and the acquistion function value as a function of time per neuron (under development). For example, to use this evaluation mode for the online code, use:

```
python run_simulations.py eval
```
Simply leave the second keyword blank to run normally.

